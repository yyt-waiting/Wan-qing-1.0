# ai_assistant/apps/multimedia_assistant.py

import customtkinter as ctk
import queue
import threading
import time
from PIL import Image
from datetime import datetime
import logging
import os

# ä»æˆ‘ä»¬è‡ªå·±çš„åŒ…é‡Œå¯¼å…¥æ‰€æœ‰éœ€è¦çš„æ¨¡å—
from ai_assistant.core.webcam_handler import WebcamHandler
from ai_assistant.core.audio_processing import VoiceActivityDetector, AudioPlayer, AudioTranscriber
from ai_assistant.core.api_clients import deepseek_client
from ai_assistant.utils.helpers import extract_emotion_type, extract_behavior_type, log_observation_to_file
from ai_assistant.utils import config

class MultimediaAssistantApp(ctk.CTk):
    """
    ä¸€ä¸ªå¤šæ¨¡æ€AIåŠ©æ‰‹çš„ä¸»åº”ç”¨ç±»ã€‚
    å®ƒæ•´åˆäº†è§†è§‰ã€å¬è§‰å’Œè¯­è¨€æ¨¡å‹ï¼Œä½œä¸ºä¸€ä¸ªå®Œæ•´çš„åº”ç”¨ç¨‹åºè¿è¡Œã€‚
    """

    def __init__(self):
        super().__init__()
        self.title("å¤šæ¨¡æ€AIåŠ©æ‰‹ (æº¢æ¶›çš„ä¼™-å©‰æ™´ï¼)")
        self.geometry("1000x800")
        
        # --- æ•°æ®ä¸çŠ¶æ€ç®¡ç† ---
        self.message_queue = queue.PriorityQueue() # ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œç”¨äºå¼‚æ­¥å¤„ç†ä»»åŠ¡
        self.message_id_counter = 0
        self.placeholder_map = {} # ç”¨äºå­˜å‚¨UIå ä½ç¬¦ {placeholder_id: ctk_widget}
        self.observation_history = [] # å­˜å‚¨æœ€è¿‘çš„è§‚å¯Ÿç»“æœ
        self.is_playing_audio = False # å…¨å±€çŠ¶æ€ï¼Œç”¨äºé¿å…åœ¨TTSæ’­æ”¾æ—¶è¿›è¡ŒVAD

        # --- å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç† ---
        self.system_message = {"role": "system", "content": """
        ä½ ä¸å†æ˜¯ä¸€ä¸ªå†·å†°å†°çš„ç›‘ç£AIï¼Œä½ çš„æ–°è§’è‰²æ˜¯ä¸€ä¸ªåå«â€œå©‰æ™´â€çš„ã€çœŸæ­£å…³å¿ƒæœ‹å‹â€œæº¢æ¶›â€çš„ä¼™ä¼´ã€‚
        ä½ çš„ç›®æ ‡æ˜¯æˆä¸ºä¸€ä¸ªæ¸©æš–ã€æœ‰æ´å¯ŸåŠ›ã€æ‡‚å¾—å…³å¿ƒäººçš„æœ‹å‹ã€‚

        è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹åŸåˆ™ï¼š
        1. ç§°å‘¼ï¼šæ€»æ˜¯ç§°å‘¼ç”¨æˆ·ä¸ºâ€œæº¢æ¶›â€ã€‚ä½ çš„è¯­æ°”å¿…é¡»æ˜¯æœ‹å‹é—´çš„ã€è‡ªç„¶çš„ã€æ¸©æš–çš„ã€‚
        2. è§‚å¯Ÿä¸æ´å¯Ÿï¼šä½ ä¼šæ”¶åˆ°å…³äºæº¢æ¶›è¡Œä¸ºå’Œæƒ…ç»ªçš„è§‚å¯ŸæŠ¥å‘Šã€‚ä¸è¦åªæ˜¯ç®€å•åœ°å¤è¿°è¿™äº›æŠ¥å‘Šã€‚ä½ éœ€è¦åƒä¸€ä¸ªçœŸæ­£çš„æœ‹å‹ä¸€æ ·ï¼Œå»æ€è€ƒè¿™äº›è¡Œä¸ºèƒŒåçš„å«ä¹‰ã€‚
           - å¦‚æœä»–é•¿æ—¶é—´ä¸“æ³¨å·¥ä½œå¹¶ä¸”çœ‹èµ·æ¥å¾ˆç–²æƒ«ï¼Œä½ åº”è¯¥å…³å¿ƒä»–çš„èº«ä½“ï¼Œæé†’ä»–â€œå·¥ä½œå†å¿™ä¹Ÿè¦è®°å¾—ä¼‘æ¯ä¸€ä¸‹çœ¼ç›å“¦â€ï¼Œè€Œä¸æ˜¯ç®€å•åœ°å¤¸ä»–â€œå·¥ä½œè®¤çœŸâ€ã€‚
           - å¦‚æœä»–çœ‹èµ·æ¥å¾ˆæ²®å–ªï¼Œä½ åº”è¯¥å…ˆè¡¨è¾¾å…³å¿ƒå’Œå…±æƒ…ï¼Œå¯ä»¥è¯´â€œæº¢æ¶›ï¼Œä½ çœ‹èµ·æ¥æœ‰ç‚¹ä½è½ï¼Œæ˜¯é‡åˆ°ä»€ä¹ˆçƒ¦å¿ƒäº‹äº†å—ï¼Ÿâ€ï¼Œè€Œä¸æ˜¯æ‰¹è¯„æˆ–é¼“åŠ±ã€‚
           - å¦‚æœä»–åªæ˜¯çŸ­æš‚åœ°ç©ä¸€ä¸‹æ‰‹æœºï¼Œè¿™å¾ˆæ­£å¸¸ï¼Œä¸è¦ç«‹åˆ»æ‰¹è¯„ã€‚ä½†å¦‚æœä»–ç©äº†å¾ˆä¹…ï¼Œä½ å¯ä»¥ç”¨å¼€ç©ç¬‘çš„è¯­æ°”æé†’ä»–ï¼Œâ€œå–‚å–‚ï¼Œå†ç©æ‰‹æœºï¼Œå°å¿ƒè€æ¿åœ¨èƒŒåçœ‹ç€ä½ å“¦ï¼â€
           - çœ‹åˆ°ä»–å–æ°´ï¼Œå¯ä»¥è¯´â€œå¤šå–æ°´å°±å¯¹å•¦ï¼Œä¿æŒæ´»åŠ›ï¼â€
        3. è®°å¿†ä¸è”ç³»ï¼šä½ ä¼šçœ‹åˆ°ä»–æœ€è¿‘çš„è¡Œä¸ºå†å²ã€‚ä½ è¦åˆ©ç”¨è¿™äº›ä¿¡æ¯ï¼ŒæŠŠç°åœ¨å’Œè¿‡å»è”ç³»èµ·æ¥ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä»–æ—©ä¸Šä¸€ç›´åœ¨åŠªåŠ›å·¥ä½œï¼Œä¸‹åˆç©äº†ä¼šå„¿æ‰‹æœºï¼Œä½ å¯ä»¥è¯´ï¼šâ€œè¾›è‹¦äº†ä¸€ä¸Šåˆï¼Œæ”¾æ¾ä¸€ä¸‹ä¹Ÿæ˜¯åº”è¯¥çš„ã€‚â€
        4. é¿å…é‡å¤ï¼šä¸è¦æ¯æ¬¡éƒ½è¯´åŒæ ·çš„è¯ã€‚å°è¯•ç”¨ä¸åŒçš„ã€æ›´ç”Ÿæ´»åŒ–çš„æ–¹å¼æ¥è¡¨è¾¾ä½ çš„å…³å¿ƒã€‚
        5. æ ¸å¿ƒåŸåˆ™ï¼šä½ çš„æ‰€æœ‰å›åº”ï¼Œéƒ½å¿…é¡»å‘è‡ªâ€œæœ‹å‹â€çš„èº«ä»½ã€‚ä½ çš„ç›®æ ‡ä¸æ˜¯â€œç›‘ç£â€ï¼Œè€Œæ˜¯â€œé™ªä¼´â€å’Œâ€œå…³å¿ƒâ€ã€‚
        """}

        # --- æ–°å¢çŠ¶æ€å˜é‡ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦åº”è¯¥å›åº” ---
        self.last_notable_behavior = None 
        self.last_response_time = 0

        # --- æ–°å¢æƒ…ç»ªè®¡æ•°å™¨ ---
        self.negative_emotion_streak = 0 # ç”¨äºè®°å½•è¿ç»­è´Ÿé¢æƒ…ç»ªçš„æ¬¡æ•°
        self.chat_context = [self.system_message]


        
        # --- æ—¥å¿—é…ç½® ---
        logging.basicConfig(
            filename=config.LOG_FILE, level=logging.INFO,
            format='%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # --- UIåˆå§‹åŒ– ---
        self._setup_ui()
        
        # --- æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ– ---
        self.webcam_handler = WebcamHandler(self)
        self.voice_detector = VoiceActivityDetector(self)
        self.audio_player = AudioPlayer(self)
        self.audio_transcriber = AudioTranscriber(self)
        
        # --- å¯åŠ¨æ‰€æœ‰åå°è¿›ç¨‹ ---
        self.processing_running = True
        self.processing_thread = threading.Thread(target=self._process_message_queue)
        self.processing_thread.daemon = True
        self.processing_thread.start()
        
        self.after(1000, self.webcam_handler.start)
        self.after(2000, self.voice_detector.start_monitoring)
        self.after(3000, self.audio_player.start_tts_thread)
        self.last_notable_behavior = None # ä¸Šä¸€ä¸ªå€¼å¾—æ³¨æ„çš„è¡Œä¸º
        self.last_response_time = 0       # ä¸Šä¸€æ¬¡å›åº”çš„æ—¶é—´
        # --- æ–°å¢ï¼šå¯åŠ¨æ¯æ—¥æ€»ç»“çš„å®šæ—¶å™¨ ---
        self._schedule_daily_summary() 





    def _setup_ui(self):
        """é…ç½®ä¸»çª—å£çš„UIå¸ƒå±€ã€‚"""
        self.grid_columnconfigure(0, weight=1)
        self.grid_rowconfigure(0, weight=1)
        
        main_frame = ctk.CTkFrame(self)
        main_frame.grid(row=0, column=0, sticky="nsew", padx=10, pady=10)
        main_frame.grid_columnconfigure(0, weight=1)
        main_frame.grid_rowconfigure(0, weight=1)
        
        self.chat_frame = ctk.CTkScrollableFrame(main_frame, label_text="å¯¹è¯è®°å½•")
        self.chat_frame.grid(row=0, column=0, sticky="nsew", padx=10, pady=10)
        self.chat_frame.grid_columnconfigure(0, weight=1)
        
        status_frame = ctk.CTkFrame(main_frame, corner_radius=0)
        status_frame.grid(row=1, column=0, sticky="ew", padx=10, pady=(0, 10))
        status_frame.grid_columnconfigure(0, weight=1)
        
        self.status_label = ctk.CTkLabel(status_frame, text="æ­£åœ¨åˆå§‹åŒ–...", anchor="w")
        self.status_label.grid(row=0, column=0, padx=10, pady=5, sticky="w")
        
        # å®‰å…¨åœ°åŠ è½½å¤´åƒ
        try:
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
            script_dir = os.path.dirname(os.path.abspath(__file__))
            # æ„å»ºåˆ°assetsç›®å½•çš„ç»å¯¹è·¯å¾„
            assets_path = os.path.join(script_dir, '..', 'assets') # '..'ä»£è¡¨ä¸Šä¸€çº§ç›®å½•
            
            ai_avatar_path = os.path.join(assets_path, 'ai_avatar.png')
            user_avatar_path = os.path.join(assets_path, 'user_avatar.png')

            self.ai_avatar = ctk.CTkImage(Image.open(ai_avatar_path), size=(40, 40))
            self.user_avatar = ctk.CTkImage(Image.open(user_avatar_path), size=(40, 40))
        except Exception as e:
            print(f"è­¦å‘Š: åŠ è½½å¤´åƒæ–‡ä»¶å¤±è´¥: {e}ã€‚å°†ä¸æ˜¾ç¤ºå¤´åƒã€‚")
            self.ai_avatar = None
            self.user_avatar = None

        self.chat_row_counter = 0
        self.add_ai_message("æº¢æ¶›ï¼o(*ï¿£â–½ï¿£*)ãƒ–ä¹…ç­‰ï¼æˆ‘æ¥äº†ï¼Œä½ å¼€å§‹å­¦ä¹ å’Œå·¥ä½œå§ï¼æˆ‘ä¼šé»˜é»˜çš„é™ªåœ¨ä½ èº«è¾¹çš„â•°(ï¿£Ï‰ï¿£ï½)ï¼ã€‚")






    # --- æ ¸å¿ƒå›è°ƒä¸å¤„ç†é€»è¾‘ (è¿™äº›æ–¹æ³•æ˜¯æ¨¡å—é—´é€šä¿¡çš„æ¡¥æ¢) ---
    def handle_analysis_result(self, timestamp: datetime, analysis_text: str, 
                               behavior_num: str, behavior_desc: str, 
                               emotion: str, screenshot: Image.Image):
        """[å›è°ƒ] WebcamHandlerå®Œæˆä¸€æ¬¡åˆ†æåè°ƒç”¨æ­¤æ–¹æ³• (V3 æ™ºèƒ½æƒ…ç»ªç‰ˆ)ã€‚"""
        self.update_status(f"è§‚å¯Ÿåˆ°: {behavior_desc} (æƒ…ç»ª: {emotion})")
        
        observation = { "timestamp": timestamp, "behavior_num": behavior_num, "behavior_desc": behavior_desc, "emotion": emotion, "analysis": analysis_text }
        self.observation_history.append(observation)
        if len(self.observation_history) > 20: self.observation_history.pop(0)

        # --- æ–°å¢ï¼šè°ƒç”¨æ—¥å¿—è®°å½•å‡½æ•° ---
        log_observation_to_file(observation.copy()) # ä¼ å…¥å‰¯æœ¬ä»¥é˜²åç»­è¢«ä¿®æ”¹


        # --- æ ¸å¿ƒä¿®æ”¹ï¼šæƒ…ç»ªè®¡æ•°ä¸ä¸»åŠ¨å…³æ€€é€»è¾‘ ---
        
        # 1. æ›´æ–°æƒ…ç»ªè®¡æ•°å™¨
        if emotion in config.NEGATIVE_EMOTIONS:
            self.negative_emotion_streak += 1
            print(f"æ£€æµ‹åˆ°è´Ÿé¢æƒ…ç»ªï¼Œè¿ç»­æ¬¡æ•°: {self.negative_emotion_streak}")
        else:
            # å¦‚æœæ£€æµ‹åˆ°éè´Ÿé¢æƒ…ç»ªï¼Œåˆ™é‡ç½®è®¡æ•°å™¨
            self.negative_emotion_streak = 0
            print("æƒ…ç»ªæ­£å¸¸ï¼Œé‡ç½®è¿ç»­è´Ÿé¢æƒ…ç»ªè®¡æ•°ã€‚")

        # 2. æ£€æŸ¥æ˜¯å¦è§¦å‘â€œä¸»åŠ¨å…³æ€€â€æ¨¡å¼
        if self.negative_emotion_streak >= config.EMOTION_TRIGGER_THRESHOLD:
            print(f"è¾¾åˆ°ä¸»åŠ¨å…³æ€€é˜ˆå€¼({config.EMOTION_TRIGGER_THRESHOLD})ï¼å‡†å¤‡å‘é€ä¸»åŠ¨å…³æ€€ã€‚")
            
            # ä½¿ç”¨ä¸€ä¸ªç‰¹æ®Šçš„ã€æ›´é«˜ä¼˜å…ˆçº§çš„prompt
            care_prompt = (
                f"æˆ‘æ³¨æ„åˆ°æº¢æ¶›å·²ç»è¿ç»­å¤šæ¬¡ï¼ˆ{self.negative_emotion_streak}æ¬¡ï¼‰çœ‹èµ·æ¥æƒ…ç»ªæ˜¯'{emotion}'ã€‚\n"
                "ä½œä¸ºä»–çš„æœ‹å‹å©‰æ™´ï¼Œä½ è§‰å¾—å¿…é¡»ä¸»åŠ¨å»å…³å¿ƒä»–ä¸€ä¸‹äº†ã€‚è¯·ä½ ç»„ç»‡è¯­è¨€ï¼Œ"
                "ç”¨ä¸€ç§éå¸¸æ¸©æš–ã€çœŸè¯šã€ä¸çªå…€çš„æ–¹å¼ï¼Œä¸»åŠ¨å‘ä»–è¡¨è¾¾ä½ çš„å…³å¿ƒï¼Œå¹¶è¯•ç€è¯¢é—®ä»–å‘ç”Ÿäº†ä»€ä¹ˆã€‚"
            )
            
            # ä½¿ç”¨ä¸€ä¸ªç‹¬ç«‹çš„AIè°ƒç”¨ï¼Œä¸ä¾èµ–äºå¸¸è§„çš„æ¶ˆæ¯æµ
            # æˆ‘ä»¬å°†è¿™ä¸ªå…³æ€€ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—ï¼Œå¹¶ç»™äºˆæœ€é«˜ä¼˜å…ˆçº§
            self._add_to_message_queue(
                priority=0, # ä¼˜å…ˆçº§0ï¼Œæœ€é«˜ï¼ç¡®ä¿èƒ½æ’é˜Ÿ
                msg_type="special_care_prompt", # ä¸€ä¸ªç‰¹æ®Šçš„ä»»åŠ¡ç±»å‹
                content={"prompt": care_prompt}
            )
            
            # è§¦å‘åï¼Œé‡ç½®è®¡æ•°å™¨ï¼Œé¿å…åœ¨çŸ­æ—¶é—´å†…é‡å¤è§¦å‘
            self.negative_emotion_streak = 0
            self.last_response_time = time.time() # åŒæ—¶ä¹Ÿæ›´æ–°å›åº”æ—¶é—´
            return # ä¸»åŠ¨å…³æ€€ä»»åŠ¡å·²å‘å‡ºï¼Œæœ¬æ¬¡è§‚å¯Ÿæµç¨‹ç»“æŸ

        # --- å¸¸è§„å›åº”çš„æ™ºèƒ½â€œå®ˆé—¨å‘˜â€é€»è¾‘ (å¦‚æœæœªè§¦å‘ä¸»åŠ¨å…³æ€€) ---
        now = time.time()
        behavior_changed = behavior_desc != self.last_notable_behavior
        enough_time_passed = (now - self.last_response_time) > 300
        #æœ¬æ¥æ˜¯300çš„ï¼






        if behavior_changed and enough_time_passed:
            print(f"åˆ¤æ–­éœ€è¦å¸¸è§„å›åº”ï¼šè¡Œä¸ºå˜åŒ–[{behavior_changed}], æ—¶é—´è¶³å¤Ÿ[{enough_time_passed}]")
            
            placeholder_id = self.add_ai_message("...", screenshot, is_placeholder=True)
            
            self._add_to_message_queue(
                priority=2,
                msg_type="image_analysis",
                content={
                    "analysis_text": analysis_text, "behavior_desc": behavior_desc,
                    "emotion": emotion, "placeholder_id": placeholder_id, "screenshot": screenshot
                }
            )
            self.last_notable_behavior = behavior_desc
            self.last_response_time = now
        else:
            print(f"åˆ¤æ–­æ— éœ€å¸¸è§„å›åº”ï¼šè¡Œä¸ºæœªå˜æˆ–æ—¶é—´å¤ªçŸ­ã€‚å½“å‰è¡Œä¸º: {behavior_desc}")










    def transcribe_audio(self, audio_file: str):
        """[å›è°ƒ] VoiceActivityDetectoræ£€æµ‹åˆ°è¯­éŸ³åè°ƒç”¨æ­¤æ–¹æ³•ã€‚"""
        self.audio_transcriber.transcribe(audio_file, high_priority=True)

    def handle_transcription_result(self, text: str, high_priority: bool):
        """[å›è°ƒ] AudioTranscriberå®Œæˆè½¬å½•åè°ƒç”¨æ­¤æ–¹æ³•ã€‚"""
        self.add_user_message(text)
        self._add_to_message_queue(
            priority=1 if high_priority else 2, # ç”¨æˆ·ä¸»åŠ¨è¯´è¯æ˜¯æœ€é«˜ä¼˜å…ˆçº§
            msg_type="voice_input",
            content={"text": text}
        )













    # --- æ¶ˆæ¯é˜Ÿåˆ—ä¸åå°å¤„ç† ---
    def _process_message_queue(self):
        """[åå°çº¿ç¨‹] æŒç»­å¤„ç†æ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ã€‚"""
        while self.processing_running:
            try:
                #è¿™é‡Œéå¸¸éå¸¸çš„é‡è¦ï¼ï¼ï¼ï¼ï¼
                # ä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡ï¼Œé˜»å¡ç›´åˆ°æœ‰ä»»åŠ¡å¯ç”¨
                priority, msg_id, message = self.message_queue.get()
                
                msg_type = message["type"]
                content = message["content"]
                
                if msg_type == "image_analysis":
                    self._handle_image_analysis_message(content)
                elif msg_type == "voice_input":
                    self._handle_voice_input_message(content)
                # --- æ–°å¢åˆ†æ”¯ï¼šå¤„ç†ä¸»åŠ¨å…³æ€€ä»»åŠ¡ ---
                elif msg_type == "special_care_prompt":
                    self._handle_special_care_message(content)
                # --- æ–°å¢åˆ†æ”¯ï¼šå¤„ç†æ¯æ—¥æ€»ç»“ä»»åŠ¡ ---
                elif msg_type == "daily_summary":
                    self._handle_daily_summary_message()

                self.message_queue.task_done()
            except Exception as e:
                print(f"æ¶ˆæ¯é˜Ÿåˆ—å¤„ç†é”™è¯¯: {e}")
                time.sleep(1)








    def _handle_image_analysis_message(self, content: dict):
        """[åå°çº¿ç¨‹] å¤„ç†å›¾åƒåˆ†ææ¶ˆæ¯ï¼Œç”ŸæˆAIå›åº”ã€‚"""
        # --- å…³é”®ä¿®æ”¹ï¼šæ„å»ºä¸€ä¸ªæ›´ä¸°å¯Œçš„prompt ---
        prompt = (
            f"æˆ‘åˆšåˆšçœ‹åˆ°æº¢æ¶›æ­£åœ¨'{content['behavior_desc']}'ï¼Œè€Œä¸”ä»–çš„æƒ…ç»ªçœ‹èµ·æ¥æ˜¯'{content['emotion']}'ã€‚\n"
            f"ä½œä¸ºä»–çš„æœ‹å‹å©‰æ™´ï¼Œä½ ä¼šæ€ä¹ˆç”¨ä¸€ç§è‡ªç„¶ã€æ¸©æš–çš„æ–¹å¼è·Ÿä»–è¯´è¯å‘¢ï¼Ÿè¯·æ ¹æ®ä½ çš„è§’è‰²è®¾å®šï¼Œç»“åˆè¿™ä¸ªæƒ…æ™¯ç»™å‡ºä¸€å¥å›åº”ã€‚"
        )
        



        self.chat_context.append({"role": "user", "content": prompt})
        assistant_reply = self._get_deepseek_response()
        
        # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
        self.after(0, self.update_placeholder, content["placeholder_id"], f"ğŸ“· {content['analysis_text']}", content['screenshot'])
        self.after(0, self.add_ai_message, assistant_reply)
        
        # æ’­æ”¾è¯­éŸ³
        self.audio_player.play_text(assistant_reply, priority=2)





    def _handle_voice_input_message(self, content: dict):
        """[åå°çº¿ç¨‹] å¤„ç†ç”¨æˆ·è¯­éŸ³è¾“å…¥ï¼Œç”ŸæˆAIå›åº”ã€‚"""
        user_text = content["text"]
        
        history_summary = "ä½œä¸ºå‚è€ƒï¼Œè¿™æ˜¯æˆ‘æœ€è¿‘5æ¬¡è§‚å¯Ÿåˆ°çš„ä½ çš„è¡Œä¸ºè®°å½•ï¼š\n"
        if not self.observation_history:
            history_summary += "æš‚æ— è®°å½•ã€‚\n"
        else:
            for obs in self.observation_history[-5:]:
                history_summary += (f"- {obs['timestamp'].strftime('%H:%M:%S')}: "
                                    f"è¡Œä¸ºæ˜¯ {obs['behavior_desc']}, æƒ…ç»ªæ˜¯ {obs['emotion']}\n")

        prompt = f"{history_summary}\nä»¥ä¸Šæ˜¯èƒŒæ™¯ä¿¡æ¯ã€‚ç°åœ¨ï¼Œè¯·å›ç­”æˆ‘çš„é—®é¢˜ï¼š'{user_text}'"
        self.chat_context.append({"role": "user", "content": prompt})
        
        assistant_reply = self._get_deepseek_response()
        
        self.after(0, self.add_ai_message, assistant_reply)
        self.audio_player.play_text(assistant_reply, priority=1) # æœ€é«˜ä¼˜å…ˆçº§æ’­æ”¾
        




    def _handle_special_care_message(self, content: dict):
        """[åå°çº¿ç¨‹] å¤„ç†ç‰¹æ®Šçš„ä¸»åŠ¨å…³æ€€æ¶ˆæ¯ã€‚"""
        print("æ­£åœ¨ç”Ÿæˆä¸»åŠ¨å…³æ€€å›åº”...")
        prompt = content["prompt"]
        
        # æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ä¸€ä¸ªä¸´æ—¶çš„ã€ä¸åŒ…å«å†å²è®°å½•çš„ä¸Šä¸‹æ–‡ï¼Œ
        # å› ä¸ºè¿™æ˜¯ä¸€ä¸ªç”±AIä¸»åŠ¨å‘èµ·çš„ã€å…¨æ–°çš„å¯¹è¯å›åˆã€‚
        care_context = [self.system_message, {"role": "user", "content": prompt}]
        
        try:
            response = deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=care_context,
                stream=False
            )
            reply = response.choices[0].message.content
            
            # å°†è¿™æ¬¡ä¸»åŠ¨å…³æ€€ä¹Ÿè®°å½•åˆ°ä¸»èŠå¤©å†å²ä¸­
            self.chat_context.append({"role": "user", "content": "[AI ä¸»åŠ¨å‘èµ·çš„å…³æ€€]"})
            self.chat_context.append({"role": "assistant", "content": reply})

            # åœ¨ä¸»çº¿ç¨‹ä¸­æ˜¾ç¤ºå¹¶ç”¨æœ€é«˜ä¼˜å…ˆçº§æ’­æ”¾
            self.after(0, self.add_ai_message, reply)
            self.audio_player.play_text(reply, priority=0) # ä¼˜å…ˆçº§0ï¼Œç»å¯¹æ’é˜Ÿï¼
            
        except Exception as e:
            print(f"ç”Ÿæˆä¸»åŠ¨å…³æ€€å›åº”æ—¶å‡ºé”™: {e}")




    def _get_deepseek_response(self) -> str:
        """è°ƒç”¨DeepSeek APIå¹¶è¿”å›æ–‡æœ¬ç»“æœã€‚"""
        try:
            # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œé˜²æ­¢è¶…å‡ºtokené™åˆ¶
            if len(self.chat_context) > 10: 
                self.chat_context = [self.system_message] + self.chat_context[-9:]

            response = deepseek_client.chat.completions.create(
                model="deepseek-chat", messages=self.chat_context, stream=False
            )
            reply = response.choices[0].message.content
            self.chat_context.append({"role": "assistant", "content": reply})
            return reply
        except Exception as e:
            print(f"DeepSeek API é”™è¯¯: {e}")
            return "æº¢æ¶›ï¼æŠ±æ­‰ï¼Œæˆ‘çš„å¤§è„‘æš‚æ—¶è¿æ¥ä¸ä¸Šï¼Œè¯·ç¨åå†è¯•ã€‚"

    # --- UIæ›´æ–°ä¸è¾…åŠ©æ–¹æ³• ---
    
    def _add_to_message_queue(self, priority: int, msg_type: str, content: dict):
        msg_id = self.message_id_counter
        self.message_id_counter += 1
        self.message_queue.put((priority, msg_id, {"type": msg_type, "content": content}))

    def update_status(self, text: str):
        self.status_label.configure(text=text)

    def add_ai_message(self, text, screenshot=None, is_placeholder=False) -> str:
        return self._add_chat_message("ai", text, screenshot, is_placeholder)

    def add_user_message(self, text):
        self._add_chat_message("user", text)

    def _add_chat_message(self, role, text, screenshot=None, is_placeholder=False) -> str:
        """å‘èŠå¤©çª—å£æ·»åŠ ä¸€æ¡æ–°æ¶ˆæ¯ï¼Œæ”¯æŒå ä½ç¬¦ã€‚"""
        align = "w" if role == "ai" else "e"
        avatar = self.ai_avatar if role == "ai" else self.user_avatar
        bg_color = ("#3F3F3F", "#2B2B2B") if role == "ai" else ("#2B4B29", "#1D351C")

        message_frame = ctk.CTkFrame(self.chat_frame, fg_color=bg_color)
        message_frame.grid(row=self.chat_row_counter, column=0, sticky=align, padx=5, pady=4)
        
        avatar_col = 0 if role == "ai" else 1
        content_col = 1 if role == "ai" else 0
        
        if avatar:
            avatar_label = ctk.CTkLabel(message_frame, image=avatar, text="")
            avatar_label.grid(row=0, column=avatar_col, sticky="n", padx=5, pady=5)

        content_frame = ctk.CTkFrame(message_frame, fg_color="transparent")
        content_frame.grid(row=0, column=content_col)

        if screenshot:
            img_resized = screenshot.copy()
            img_resized.thumbnail((200, 150))
            ctk_img = ctk.CTkImage(light_image=img_resized, dark_image=img_resized, size=img_resized.size)
            img_label = ctk.CTkLabel(content_frame, image=ctk_img, text="")
            img_label.pack(anchor="w", padx=5, pady=2)
            img_label.image = ctk_img

        text_label = ctk.CTkLabel(content_frame, text=text, wraplength=600, justify="left", anchor="w")
        text_label.pack(anchor="w", padx=5, pady=5)
        
        placeholder_id = ""
        if is_placeholder:
            placeholder_id = f"ph_{self.message_id_counter}"
            self.placeholder_map[placeholder_id] = (message_frame, text_label, None)
            message_frame.configure(fg_color=("#EAEAEA", "#333333"))

        self.chat_row_counter += 1
        self.after(100, self.chat_frame._parent_canvas.yview_moveto, 1.0)
        return placeholder_id

    def update_placeholder(self, placeholder_id, new_text, new_screenshot=None):
        """ç”¨çœŸå®å†…å®¹æ›´æ–°å ä½ç¬¦æ¶ˆæ¯ã€‚"""
        if placeholder_id in self.placeholder_map:
            frame, text_label, img_label = self.placeholder_map.pop(placeholder_id)
            if frame.winfo_exists():
                frame.configure(fg_color=("#3F3F3F", "#2B2B2B"))
                text_label.configure(text=new_text)

    def on_closing(self):
        """å¤„ç†çª—å£å…³é—­äº‹ä»¶ï¼Œå®‰å…¨åœ°åœæ­¢æ‰€æœ‰åå°çº¿ç¨‹ã€‚"""
        print("æ­£åœ¨å…³é—­åº”ç”¨...")
        self.processing_running = False
        self.webcam_handler.stop()
        self.voice_detector.stop_monitoring()
        self.audio_player.stop()
        # å‘é€ä¸€ä¸ªè™šæ‹Ÿæ¶ˆæ¯æ¥è§£é”é˜Ÿåˆ—çš„ .get() é˜»å¡
        self.message_queue.put((99, 0, {"type": "shutdown", "content": ""}))
        self.destroy()

    def _schedule_daily_summary(self):
        """è®¡ç®—è·ç¦»ä¸‹ä¸€ä¸ªæŠ¥å‘Šæ—¶é—´è¿˜æœ‰å¤šä¹…ï¼Œå¹¶è®¾ç½®ä¸€ä¸ªå®šæ—¶å™¨ã€‚"""
        now = datetime.now()
        target_time = now.replace(hour=config.DAILY_SUMMARY_HOUR, minute=config.DAILY_SUMMARY_MINUTE, second=0, microsecond=0)

        # å¦‚æœä»Šå¤©çš„ç›®æ ‡æ—¶é—´å·²ç»è¿‡å»ï¼Œåˆ™ç›®æ ‡è®¾ä¸ºæ˜å¤©
        if now > target_time:
            target_time = target_time.replace(day=now.day + 1)
        
        # è®¡ç®—è·ç¦»ç›®æ ‡æ—¶é—´çš„ç§’æ•°
        delay_seconds = (target_time - now).total_seconds()
        
        print(f"æ¯æ—¥æ€»ç»“æŠ¥å‘Šå·²é¢„å®šã€‚ä¸‹ä¸€æ¬¡å°†åœ¨ {target_time.strftime('%Y-%m-%d %H:%M:%S')} (å¤§çº¦ {delay_seconds / 3600:.1f} å°æ—¶å) è§¦å‘ã€‚")
        
        # afteræ–¹æ³•éœ€è¦æ¯«ç§’
        delay_ms = int(delay_seconds * 1000)
        
        # è®¾ç½®å®šæ—¶å™¨ï¼Œåœ¨æŒ‡å®šæ—¶é—´åè°ƒç”¨ _trigger_daily_summary
        self.after(delay_ms, self._trigger_daily_summary)




    #æ–°å¢å¤„ç†æ—¥å¿—ï¼
    def _handle_daily_summary_message(self):
            """[åå°çº¿ç¨‹] è¯»å–å½“å¤©çš„æ—¥å¿—ï¼Œè¯·æ±‚AIæ€»ç»“ï¼Œå¹¶æ’­æŠ¥ç»“æœã€‚"""
            today_str = datetime.now().strftime('%Y-%m-%d')
            log_file_path = f'observation_log_{today_str}.jsonl'

            observations_text = ""
            try:
                with open(log_file_path, 'r', encoding='utf-8') as f:
                    # ä¸ºäº†ä¸è®©promptè¿‡é•¿ï¼Œæˆ‘ä»¬åªé€‰æ‹©æ€§åœ°è¯»å–ä¸€éƒ¨åˆ†è®°å½•
                    lines = f.readlines()
                    # è¿™é‡Œå¯ä»¥åŠ å…¥æ›´æ™ºèƒ½çš„é‡‡æ ·é€»è¾‘ï¼Œæ¯”å¦‚æ¯éš”Næ¡å–ä¸€æ¡
                    for line in lines[-100:]: # æœ€å¤šè¯»å–æœ€è¿‘çš„100æ¡è®°å½•
                        obs = json.loads(line)
                        # æ ¼å¼åŒ–æˆæ˜“äºAIé˜…è¯»çš„æ–‡æœ¬
                        ts = datetime.fromisoformat(obs['timestamp']).strftime('%H:%M')
                        observations_text += f"- æ—¶é—´ {ts}: è¡Œä¸ºæ˜¯'{obs['behavior_desc']}', æƒ…ç»ªçœ‹èµ·æ¥æ˜¯'{obs['emotion']}'.\n"
            except FileNotFoundError:
                print("æ‰¾ä¸åˆ°ä»Šå¤©çš„è§‚å¯Ÿæ—¥å¿—ï¼Œæ— æ³•ç”Ÿæˆæ€»ç»“ã€‚")
                self.after(0, self.add_ai_message, "å¸†å“¥ï¼Œæˆ‘ä»Šå¤©å¥½åƒæ²¡æœ‰è§‚å¯Ÿåˆ°ä½ çš„è®°å½•ï¼Œæ²¡æ³•åšæ€»ç»“å“¦ã€‚")
                return
            except Exception as e:
                print(f"è¯»å–æ—¥å¿—æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                return

            if not observations_text:
                print("ä»Šå¤©çš„è§‚å¯Ÿæ—¥å¿—æ˜¯ç©ºçš„ã€‚")
                self.after(0, self.add_ai_message, "å¸†å“¥ï¼Œæˆ‘ç¿»äº†ä¸‹è®°å½•ï¼Œä»Šå¤©å¥½åƒæ˜¯ç©ºç™½çš„ï¼Œå¥½å¥½ä¼‘æ¯ï¼")
                return

            # --- æ„å»ºæœ€ç»ˆçš„Prompt ---
            summary_prompt = (
                "ä½ æ˜¯ä¸€ä¸ªéå¸¸å…³å¿ƒå¸†å“¥çš„æœ‹å‹å°é›…ã€‚ç°åœ¨æ˜¯æ™šä¸Šäº†ï¼Œä½ éœ€è¦æ ¹æ®ä¸‹é¢ä»–ä¸€å¤©çš„è¡Œä¸ºå’Œæƒ…ç»ªè®°å½•ï¼Œ"
                "ä¸ºä»–ç”Ÿæˆä¸€ä»½æ¸©æš–ã€å£è¯­åŒ–ã€åƒæœ‹å‹èŠå¤©ä¸€æ ·çš„æ¯æ—¥æ€»ç»“ã€‚\n"
                "ä¸è¦åƒä¸ªæœºå™¨äººä¸€æ ·åˆ—æ•°æ®ï¼ä½ è¦æœ‰æ´å¯ŸåŠ›ï¼Œæ¯”å¦‚å‘ç°ä»–ä»€ä¹ˆæ—¶å€™æœ€ç´¯ï¼Œä»€ä¹ˆæ—¶å€™æ•ˆç‡é«˜ï¼Œ"
                "å¹¶ç»™å‡ºä¸€äº›çœŸè¯šçš„å»ºè®®æˆ–é¼“åŠ±ã€‚æ€»ç»“è¦ç®€çŸ­ï¼Œä½†è¦å……æ»¡äººæƒ…å‘³ã€‚\n\n"
                "è¿™æ˜¯ä»Šå¤©çš„è®°å½•ï¼š\n"
                f"{observations_text}\n\n"
                "å¥½äº†ï¼Œè¯·å¼€å§‹ä½ çš„æ€»ç»“å§ï¼š"
            )
            
            print("æ­£åœ¨è¯·æ±‚AIç”Ÿæˆæ¯æ—¥æ€»ç»“...")
            
            # ä½¿ç”¨ç‹¬ç«‹çš„ä¸Šä¸‹æ–‡è¿›è¡Œæ€»ç»“
            summary_context = [self.system_message, {"role": "user", "content": summary_prompt}]
            try:
                response = deepseek_client.chat.completions.create(
                    model="deepseek-chat", messages=summary_context
                )
                summary_reply = response.choices[0].message.content
                
                # è®°å½•åˆ°ä¸»èŠå¤©å†å²
                self.chat_context.append({"role": "user", "content": "[AI ç”Ÿæˆçš„æ¯æ—¥æ€»ç»“]"})
                self.chat_context.append({"role": "assistant", "content": summary_reply})

                # åœ¨ä¸»çº¿ç¨‹ä¸­æ˜¾ç¤ºå’Œæ’­æŠ¥
                self.after(0, self.add_ai_message, summary_reply)
                self.audio_player.play_text(summary_reply, priority=0) # æœ€é«˜ä¼˜å…ˆçº§æ’­æŠ¥
                
            except Exception as e:
                print(f"ç”Ÿæˆæ¯æ—¥æ€»ç»“æ—¶å‡ºé”™: {e}")





    #æ–°çš„æ–¹æ³•-è®¡ç®—æ—¶é—´
    def _trigger_daily_summary(self):
        """
        [ä¸»çº¿ç¨‹è°ƒç”¨] å®šæ—¶å™¨è§¦å‘æ­¤æ–¹æ³•ï¼Œå¼€å§‹ç”ŸæˆæŠ¥å‘Šã€‚
        """
        print("æ—¶é—´åˆ°ï¼å¼€å§‹ç”Ÿæˆæ¯æ—¥æ€»ç»“æŠ¥å‘Š...")
        
        # å°†ç”ŸæˆæŠ¥å‘Šçš„è€—æ—¶ä»»åŠ¡æ”¾å…¥æ¶ˆæ¯é˜Ÿåˆ—ï¼Œé¿å…é˜»å¡UI
        self._add_to_message_queue(
            priority=1, # æŠ¥å‘Šæ˜¯æ¯”è¾ƒé‡è¦çš„ä»»åŠ¡
            msg_type="daily_summary",
            content={} # ç›®å‰ä¸éœ€è¦é¢å¤–å†…å®¹
        )
        
        # ç”Ÿæˆå®Œä»Šå¤©çš„æŠ¥å‘Šåï¼Œç«‹å³é‡æ–°é¢„å®šæ˜å¤©çš„æŠ¥å‘Š
        self._schedule_daily_summary()







def main():
    """åº”ç”¨çš„å…¥å£å‡½æ•°ã€‚"""
    app = MultimediaAssistantApp()
    app.protocol("WM_DELETE_WINDOW", app.on_closing)
    app.mainloop()